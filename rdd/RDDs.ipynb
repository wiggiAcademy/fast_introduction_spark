{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "    /*\n",
       "        WiggiMX:feel free to use it just give us the credit with a short mention :)\n",
       "    */\n",
       "    $(\"#homeButton\").remove()\n",
       "    $('body').append('<a href=\"#'+$(\"h1,h2,h3:eq(0)\").attr(\"id\")+'\" style=\"position: fixed; bottom: 10px; right: 10px;\" type=\"button\" class=\"btn btn-success btn-circle btn-lg\"><i class=\"glyphicon glyphicon-link\" id=\"homeButton\"></i></a>');\n",
       "    $(\"#MainMenu\").remove()\n",
       "    var menu = \n",
       "      '<div id=\"MainMenu\" style=\"position: fixed; top: 120px; right: 10px; z-index:6; max-height: 500px;\">'+\n",
       "        '<div class=\"list-group panel\" >'+\n",
       "          '<a href=\"#collapseMenu\" class=\"list-group-item list-group-item-success\" data-toggle=\"collapse\" data-parent=\"#MainMenu\"><img width=\"20px\" src=\"/kernelspecs/python3/logo-64x64.png\"/><i class=\"fa fa-caret-down\"></i></a>'+\n",
       "          '<div class=\"collapse\" id=\"collapseMenu\" style=\"overflow-y: overlay; max-height: 500px;\">'+\n",
       "          '</div>'+\n",
       "        '</div>'+\n",
       "      '</div>'\n",
       "   \n",
       "    var parent = $(menu)\n",
       "    var arrayIds = []\n",
       "    $(\"h1,h2,h3\").attr(\"id\",function(id,Value){\n",
       "        if(Value != \"\"){\n",
       "            var content = (Value.replace(new RegExp('-', 'g'), ' '));\n",
       "            content = \"&nbsp;\".repeat(parseInt($(this).prop(\"tagName\")[1])*2-1) + content;\n",
       "            $(parent).find(\"#collapseMenu\").append('<a href=\"#'+Value+'\" style=\"position:relative;\" class=\"list-group-item\" data-parent=\"#SubMenu1\">'+content+'</a>');\n",
       "        }\n",
       "    })\n",
       "$('body').append(parent)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "    /*\n",
    "        WiggiMX:feel free to use it just give us the credit with a short mention :)\n",
    "    */\n",
    "    $(\"#homeButton\").remove()\n",
    "    $('body').append('<a href=\"#'+$(\"h1,h2,h3:eq(0)\").attr(\"id\")+'\" style=\"position: fixed; bottom: 10px; right: 10px;\" type=\"button\" class=\"btn btn-success btn-circle btn-lg\"><i class=\"glyphicon glyphicon-link\" id=\"homeButton\"></i></a>');\n",
    "    $(\"#MainMenu\").remove()\n",
    "    var menu = \n",
    "      '<div id=\"MainMenu\" style=\"position: fixed; top: 120px; right: 10px; z-index:6; max-height: 500px;\">'+\n",
    "        '<div class=\"list-group panel\" >'+\n",
    "          '<a href=\"#collapseMenu\" class=\"list-group-item list-group-item-success\" data-toggle=\"collapse\" data-parent=\"#MainMenu\"><img width=\"20px\" src=\"/kernelspecs/python3/logo-64x64.png\"/><i class=\"fa fa-caret-down\"></i></a>'+\n",
    "          '<div class=\"collapse\" id=\"collapseMenu\" style=\"overflow-y: overlay; max-height: 500px;\">'+\n",
    "          '</div>'+\n",
    "        '</div>'+\n",
    "      '</div>'\n",
    "   \n",
    "    var parent = $(menu)\n",
    "    var arrayIds = []\n",
    "    $(\"h1,h2,h3\").attr(\"id\",function(id,Value){\n",
    "        if(Value != \"\"){\n",
    "            var content = (Value.replace(new RegExp('-', 'g'), ' '));\n",
    "            content = \"&nbsp;\".repeat(parseInt($(this).prop(\"tagName\")[1])*2-1) + content;\n",
    "            $(parent).find(\"#collapseMenu\").append('<a href=\"#'+Value+'\" style=\"position:relative;\" class=\"list-group-item\" data-parent=\"#SubMenu1\">'+content+'</a>');\n",
    "        }\n",
    "    })\n",
    "$('body').append(parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDDs\n",
    "\n",
    "Los RDDs o conjuntos de datos resilientes (**resilent distributed data sets**) se consideran la estructura de datos principal en Spark (existen otras como los data frames).Son listas distribuidas resilientes a errores.\n",
    "\n",
    "Los RDDs son distribuidos porque están particionados en los workers.\n",
    "\n",
    "Se pueden pensar como una lista a la que uno no tiene acceso directamente. \n",
    "\n",
    "<img src='images/rdd.png' width=\"50%\" height=\"50%\"/>\n",
    "\n",
    "<center>*RDD separado en 5 particiones, algunas de ellas residen en el mismo worker*</center>\n",
    "\n",
    "### Operaciones en RDDs: Transformaciones y acciones\n",
    "\n",
    "- **Transformaciones**: Son operaciones que dan como resultado un nuevo RDD. Son *lazy* ya que no se ejecutan sino hasta que tiene lugar una acción.\n",
    "- **Acciones**: Son opreaciones que dan como resultado un número. Al ejecutarlas desencadenan la serie de transformaciones previa a poder calcularla. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características\n",
    "\n",
    "<div class=\"alert alert-success alert-dismissable\" id=\"def2\">\n",
    "<a href=\"#\" class=\"close\" data-dismiss=\"alert\" aria-label=\"close\">&times;</a>\n",
    " <strong>Los RDD's son:</strong>  inmutables, particionados, tolerantes a errores, *lazy*\n",
    "</div>\n",
    "\n",
    "**Inmutable**: cada partición de un RDD es una división de datos inmutable, que no puede modificarse. En las transformaciones se crean nuevos RDDs no se transforma el original.\n",
    "\n",
    "**Particionado**: Los RDDs están divididos en partes a través de los workers\n",
    "\n",
    "**Tolerante a errores**: Spark va guardando un mapa de las transformaciones a manera de un gráfico de RDDs. En caso de que perdamos alguna partición del RDD, podemos volver a efectuar la transformación en esa partición para lograr computar de nuevo la transformación.\n",
    "\n",
    "***Lazy***: Las transformaciones sólo se llevaran a cabo al correr una acción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de RDDs\n",
    "El gráfico de RDDs define el linaje de los RDDs. Por ejemplo:\n",
    "\n",
    "```Python\n",
    "firstRDD = spark.textFile(\"hdfs://...\")\n",
    "secondRDD = firstRDD.filter(someFunction);\n",
    "thirdRDD = secondRDD.map(someFunction);\n",
    "result = thirdRDD.count()\n",
    "```\n",
    "\n",
    "![Rdd Graph](./images/RDD_graph.png)\n",
    "Example taken from ([saurzcode](https://saurzcode.in/2015/10/what-is-rdd-in-spark-and-why-do-we-need-it/))\n",
    "\n",
    "Una vez que inicializamos el SparkContext hay tres formas generales de crear un RDD:\n",
    "\n",
    "a) Leer un RDD desde archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "spark = SparkSession \\\n",
    "       .builder.master(\"local[*]\") \\\n",
    "       .appName(\"RDD\") \\\n",
    "       .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFile = sc.textFile(\"input.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Usar parallelize ya sea para un archivo o arreglo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileString = open('data/Amounts.txt','r').read().split('\\n')\n",
    "numbersStrRDD = sc.parallelize(fileString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(numbersStrRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miFirstRDD = sc.parallelize([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25])\n",
    "type(miFirstRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alert-dismissable\" id=\"def2\">\n",
    "<a href=\"#\" class=\"close\" data-dismiss=\"alert\" aria-label=\"close\">&times;</a>\n",
    " Dado que los RDDs no tienen un orden definido, las operaciones en ellos <strong>no deben depender del orden de los elementos en las listas ni del orden en el que se efectúan las operaciones</strong></div>\n",
    " \n",
    " ## Más sobre operaciones con RDDs\n",
    " \n",
    "- **Transformaciones**: Son operaciones que dan como resultado un nuevo RDD. Son *lazy* ya que no se ejecutan sino hasta que tiene lugar una acción.\n",
    "- **Acciones**: Son opreaciones que dan como resultado un número. Al ejecutarlas desencadenan la serie de transformaciones previa a poder calcularla. \n",
    "\n",
    "![OperacionesRDDs](./images/RddOperations.png)\n",
    "\n",
    "* **collect()**: Esta operación regresa a la memoria local los elmentos que están distribuidos en el clúster como una lista secuencial.\n",
    "\n",
    "<div class=\"alert alert-success alert-dismissable\" id=\"def2\">\n",
    "<a href=\"#\" class=\"close\" data-dismiss=\"alert\" aria-label=\"close\">&times;</a>\n",
    " <strong>Si tenemos muchos datos (masivos) esta operación puede matar nuestra memoria x_x</strong></div>\n",
    "\n",
    "* **take(número n chiquito)**: Está función hace un collect de n elelemntos arbitrarios del conjunto de datos y los acomoda en memoria local. No es determinista por lo que puede ser que se obtengan distintos sets de datos cada vez.\n",
    "\n",
    "**Ejemplo**: Obteniendo elementos de un RDD a la memoria local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "Take: [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "print('Collect: '+str(miFirstRDD.collect()))\n",
    "print('Take: '+str(miFirstRDD.take(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map \n",
    "---\n",
    "\n",
    "map es un tipo de  **transformación** que crea un nuevo data set a partic de uno ya existente por medio de un **mapeo uno a uno**.\n",
    "\n",
    "#### Nota: Operador Lambda\n",
    "\n",
    "En python y scala las operaciones **map**, **reduce** y **filter**se aplican a través de expresiones a través del operador lambda. El operador lambda o función lambda nos permite crear funciones anónimas (sólo necesarias donde se crearon).\n",
    "\n",
    "Reordemos la sintaxis general de una función lambda:\n",
    "\n",
    "**lambda** lista de argumentos: **expression**.\n",
    "\n",
    "Más info del operador lambda: [http://www.python-course.eu/lambda.php]\n",
    "\n",
    "** Example: Map Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['594.38', '281.37', '144.85', '20.99', '797.40']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbersStrRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[594.38, 281.37, 144.85, 20.99, 797.4]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casting the elements of the RDD into a distributes way\n",
    "floatsRDD = numbersStrRDD.map(lambda x: float(x))\n",
    "floatsRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "1.¿Cómo calcularías en el RDD \"l\" la suma de los cuadrados de los elementos?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=sc.parallelize([1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tuviera python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "functools.reduce(lambda x,y: x+y, map(lambda i:i*i,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En spark, ¿cómo sería si consideramos que map y reduce se aplican de la siguiente manera?\n",
    "```Python\n",
    "rdd.map(lambda function)\n",
    "rdd.reduce(lambda function)\n",
    "```\n",
    "\n",
    "**pista**: en Spark las operaciones suelen seriarse de izquierda derecha usand el punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l.map(lambda i:i*i).reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Recordando map y reduce y cómo se efectuan en python, dado el siguiente RDD, ¿cuál de las siguientes operaciones computa el promedio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l.reduce(lambda x,y: x+y)/l.map(lambda x:1).reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l.reduce(lambda x,y: x+y)/l.map(lambda x:x).reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l.reduce(lambda x,y: x+y)/l.reduce(lambda x,y: x+y).map(lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l.reduce(lambda x,y: x+y)/l.reduce(lambda x,y: 1+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cuidado al reducir operaciones..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C=sc.parallelize([1,1,2])\n",
    "C.reduce(lambda x,y: x*x+y*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C=sc.parallelize([1,1,2])\n",
    "C.map(lambda x: x*x).reduce(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con las operaciones se puede obtener información sobre un RDD sin necesidad de desplegarlo todo o hacer un collect\n",
    "### count\n",
    "Para saber cuántos elementos hay en un RDD, pero si el set de datos es muy grande puede ser problemático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=1000000\n",
    "B=sc.parallelize([1,2,3,4]*int(n/4))\n",
    "B.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### primeros elementos (poquitos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtener los primeros elementos de un RDD\n",
    "print('first element=',B.first())\n",
    "print('first 5 elements = ',B.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saber si hay entradas en el RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B.isEmpty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conocer un aproximado del número de elementos en el RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B.countApprox(100,confidence=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=5\n",
    "# First argument: with or without replacement , second argument: with what probability we are going to get each element\n",
    "print('sample=',B.sample(False,m/n).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado\n",
    "Regresa un nuevo RDD en el que una condición se cumple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('El número de elementos en B que son  > 3 =',B.filter(lambda n: n > 3).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distinct\n",
    "Quitar elementos duplicados en el RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remover elementos duplicados en DuplicateRDD\n",
    "DuplicateRDD = sc.parallelize([1,1,2,2,3,3])\n",
    "print('DuplicateRDD=',DuplicateRDD.collect())\n",
    "print('DistinctRDD = ',DuplicateRDD.distinct().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flatmap\n",
    "Hace una lista con todos los elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map: [['you', 'are', 'my', 'sunshine'], ['my', 'only', 'sunshine']]\n",
      "flatmap: ['you', 'are', 'my', 'sunshine', 'my', 'only', 'sunshine']\n"
     ]
    }
   ],
   "source": [
    "text=[\"you are my sunshine\",\"my only sunshine\"]\n",
    "text_file = sc.parallelize(text)\n",
    "# mapea cada línea en el texto a una lista de palabras\n",
    "print('map:',text_file.map(lambda line: line.split(\" \")).collect())\n",
    "# crea una sola lista de palabras al combinar las palabras de todas las líneas\n",
    "print('flatmap:',text_file.flatMap(lambda line: line.split(\" \")).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones de conjuntos\n",
    "union, intersection, subtraction, cartesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize([1, 1, 2, 3])\n",
    "rdd2 = sc.parallelize([1, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### union\n",
    "Regresa la unión de un RDD con otro.\n",
    "Se permiten las repeticiones. Los RDDs son como bolsas más que conjuntos.\n",
    "Para convertir el resultado en un conjunto use .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1= [1, 1, 2, 3]\n",
      "rdd2= ['a', 'b', 1]\n",
      "union as bags = [1, 1, 2, 3, 'a', 'b', 1]\n",
      "union as sets = [2, 'b', 1, 3, 'a']\n"
     ]
    }
   ],
   "source": [
    "rdd2=sc.parallelize(['a','b',1])\n",
    "print('rdd1=',rdd1.collect())\n",
    "print('rdd2=',rdd2.collect())\n",
    "print('union as bags =',rdd1.union(rdd2).collect())\n",
    "print('union as sets =',rdd1.union(rdd2).distinct().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intersection\n",
    "Intersección. Selecciona los elementos en común entre dos RDDs. La intersección no contiene elementos repetidos, ya que efectúa un distinct internamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1= [1, 1, 2, 3]\n",
      "rdd2= [1, 1, 2, 5]\n",
      "intersection= [2, 1]\n"
     ]
    }
   ],
   "source": [
    "rdd2=sc.parallelize([1,1,2,5])\n",
    "print('rdd1=',rdd1.collect())\n",
    "print('rdd2=',rdd2.collect())\n",
    "print('intersection=',rdd1.intersection(rdd2).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subtract\n",
    "Regresa todos los elementos en un RDD que no están contenidos en el otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1= [1, 1, 2, 3]\n",
      "rdd2= [1, 1, 2, 5]\n",
      "rdd1.subtract(rdd2)= [3]\n"
     ]
    }
   ],
   "source": [
    "print('rdd1=',rdd1.collect())\n",
    "print('rdd2=',rdd2.collect())\n",
    "print('rdd1.subtract(rdd2)=',rdd1.subtract(rdd2).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cartesian\n",
    "Regresa un RDD con todos los pareds de elementos (a,b), donde a está en el RDD del que se manda a llamar el método cartesian y b está en el otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1= [1, 1, 2]\n",
      "rdd2= ['a', 'b']\n",
      "rdd1.cartesian(rdd2)=\n",
      " [(1, 'a'), (1, 'b'), (1, 'a'), (1, 'b'), (2, 'a'), (2, 'b')]\n"
     ]
    }
   ],
   "source": [
    "rdd1=sc.parallelize([1,1,2])\n",
    "rdd2=sc.parallelize(['a','b'])\n",
    "print('rdd1=',rdd1.collect())\n",
    "print('rdd2=',rdd2.collect())\n",
    "print('rdd1.cartesian(rdd2)=\\n',rdd1.cartesian(rdd2).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuente\n",
    "<a src=\"https://github.com/LiberPH\">PhD Libertad</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
