{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "    /*\n",
       "        WiggiMX:feel free to use it just give us the credit with a short mention :)\n",
       "    */\n",
       "    $(\"#homeButton\").remove()\n",
       "    $('body').append('<a href=\"#'+$(\"h1,h2,h3:eq(0)\").attr(\"id\")+'\" style=\"position: fixed; bottom: 10px; right: 10px;\" type=\"button\" class=\"btn btn-success btn-circle btn-lg\"><i class=\"glyphicon glyphicon-link\" id=\"homeButton\"></i></a>');\n",
       "    $(\"#MainMenu\").remove()\n",
       "    var menu = \n",
       "      '<div id=\"MainMenu\" style=\"position: fixed; top: 120px; right: 10px; z-index:6; max-height: 500px;\">'+\n",
       "        '<div class=\"list-group panel\" >'+\n",
       "          '<a href=\"#collapseMenu\" class=\"list-group-item list-group-item-success\" data-toggle=\"collapse\" data-parent=\"#MainMenu\"><img width=\"40px\" src=\"/kernelspecs/python3/logo-64x64.png\"/><i class=\"fa fa-caret-down\"></i></a>'+\n",
       "          '<div class=\"collapse\" id=\"collapseMenu\" style=\"overflow-y: overlay; max-height: 500px;\">'+\n",
       "          '</div>'+\n",
       "        '</div>'+\n",
       "      '</div>'\n",
       "   \n",
       "    var parent = $(menu)\n",
       "    var arrayIds = []\n",
       "    $(\"h1,h2,h3\").attr(\"id\",function(id,Value){\n",
       "        if(Value != \"\"){\n",
       "            var content = (Value.replace(new RegExp('-', 'g'), ' '));\n",
       "            content = \"&nbsp;\".repeat(parseInt($(this).prop(\"tagName\")[1])*2-1) + content;\n",
       "            $(parent).find(\"#collapseMenu\").append('<a href=\"#'+Value+'\" style=\"position:relative;\" class=\"list-group-item\" data-parent=\"#SubMenu1\">'+content+'</a>');\n",
       "        }\n",
       "    })\n",
       "$('body').append(parent)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "    /*\n",
    "        WiggiMX:feel free to use it just give us the credit with a short mention :)\n",
    "    */\n",
    "    $(\"#homeButton\").remove()\n",
    "    $('body').append('<a href=\"#'+$(\"h1,h2,h3:eq(0)\").attr(\"id\")+'\" style=\"position: fixed; bottom: 10px; right: 10px;\" type=\"button\" class=\"btn btn-success btn-circle btn-lg\"><i class=\"glyphicon glyphicon-link\" id=\"homeButton\"></i></a>');\n",
    "    $(\"#MainMenu\").remove()\n",
    "    var menu = \n",
    "      '<div id=\"MainMenu\" style=\"position: fixed; top: 120px; right: 10px; z-index:6; max-height: 500px;\">'+\n",
    "        '<div class=\"list-group panel\" >'+\n",
    "          '<a href=\"#collapseMenu\" class=\"list-group-item list-group-item-success\" data-toggle=\"collapse\" data-parent=\"#MainMenu\"><img width=\"40px\" src=\"/kernelspecs/python3/logo-64x64.png\"/><i class=\"fa fa-caret-down\"></i></a>'+\n",
    "          '<div class=\"collapse\" id=\"collapseMenu\" style=\"overflow-y: overlay; max-height: 500px;\">'+\n",
    "          '</div>'+\n",
    "        '</div>'+\n",
    "      '</div>'\n",
    "   \n",
    "    var parent = $(menu)\n",
    "    var arrayIds = []\n",
    "    $(\"h1,h2,h3\").attr(\"id\",function(id,Value){\n",
    "        if(Value != \"\"){\n",
    "            var content = (Value.replace(new RegExp('-', 'g'), ' '));\n",
    "            content = \"&nbsp;\".repeat(parseInt($(this).prop(\"tagName\")[1])*2-1) + content;\n",
    "            $(parent).find(\"#collapseMenu\").append('<a href=\"#'+Value+'\" style=\"position:relative;\" class=\"list-group-item\" data-parent=\"#SubMenu1\">'+content+'</a>');\n",
    "        }\n",
    "    })\n",
    "$('body').append(parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames\n",
    "\n",
    "En Spark 2.0 y otras versiones más recientes los DataFrames son el \"caballito de batalla\" y la forma principal de trabajar con Python y Spark en conjunto.\n",
    "\n",
    "<div class=\"alert alert-info\">Los <strong>DataFrames</strong> funcionan como tablas o DataFrames de pandas, ya que se comportan como si tuvieran filas y columnas. En realidad son filas distribuidas.</div>\n",
    "\n",
    "Usar **DataFrames** proporciona varias ventajas:\n",
    "* Sintaxis más simple que la de los RDDs\n",
    "* Posibilidad de usar comandos tipo SQL directamente sobre el DataFrame\n",
    "* Las operaciones están automáticamente distribuidas en los RDDs\n",
    " \n",
    "La principal ventaja de usar los DataFrames de Spark sobre Pandas o cualquier otra cosa es que Spark puede manipular datos a través de muchos RDDs, cantidades masivas de datos que nocaben en una sola computadora. El costo por esto es una sintaxis un poquito rara, pero nada terrible.\n",
    "\n",
    "## Para crear un DataFrame\n",
    "\n",
    "Primero necesitamos importar una SparkSession:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://8e07f903780f:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initiallizing Spark (just run once) https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-sparkcontext-creating-instance-internals.html\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">La **SparkSession** nos permite accesar a todas las funcionalidades de Spark (incluyendo Data frames), mientras que el Spark Context no incluye DataFrames.</div>\n",
    "\n",
    "Luego, inicializar la SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puede que tome un tiempo en una computadora local\n",
    "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear un data frae necesitamos alguna de las siguientes opciones:\n",
    "* Obtener datos de un archivo.\n",
    "* Conectarnos a un archivo grande y distribuido (como HDFS).\n",
    "* Convertir un RDD en DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos a empezar con cómo leer desde un archivo\n",
    "\n",
    "df = spark.read.json('./data/people2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostrar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Michael</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>Andy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>Justin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age     name\n",
       "0   NaN  Michael\n",
       "1  30.0     Andy\n",
       "2  19.0   Justin"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'name']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, age: string, name: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo sé qué otros métodos hay para mi DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: bigint, name: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "  Para DataFrames no tenemos <strong>isEmpty</strong> ni <strong>countApprox</strong>, por lo que si queremos conocer si contiene datos nuestroDataFrame es recomendable convertirlo en RDD primero. En general no es buena idea hacer un <strong>collect</strong> o un <strong>count</strong> en DataFrames cuya magnitud no conocemos.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.isEmpty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esquema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunos tipos de datos como los formatos tabulares de csv, es muy fácil inferir un esquema, pero es posible que sea necesario definir el esquema manualmente si se planea utilizar un métodt .read que no tenga la capacidad de inferir un esquema (inferSchema)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark cuenta con las herramientas para realizar lo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField,StringType,IntegerType,StructType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que cargamos las herramientas necesitamos crear la lista de los campos estructurados (StructFields): \n",
    "* :param name: string, nombre del campo.\n",
    "* :param dataType: :class:`DataType` del campo.\n",
    "* :param nullable: boolean, Si puede ser nulo (None) o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField(\"age\", IntegerType(), True),StructField(\"name\", StringType(), True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el esquema por completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_struc = StructType(fields=data_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y por último asignamos el esquema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json('data/people2.json', schema=final_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccionar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'age'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.select('age'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| age|\n",
      "+----+\n",
      "|null|\n",
      "|  30|\n",
      "|  19|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=None, name='Michael'), Row(age=30, name='Andy')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns list of Row objects\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar múltiples columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, name: string]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(['age','name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['age','name']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear nuevas columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+------+\n",
      "| age|   name|newage|\n",
      "+----+-------+------+\n",
      "|null|Michael|  null|\n",
      "|  30|   Andy|    30|\n",
      "|  19| Justin|    19|\n",
      "+----+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agregar una nueva columna que es una copia de otra\n",
    "df.withColumn('newage',df['age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|supernewage|   name|\n",
      "+-----------+-------+\n",
      "|       null|Michael|\n",
      "|         30|   Andy|\n",
      "|         19| Justin|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renombrar una columna\n",
    "df.withColumnRenamed('age','supernewage').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algunas operaciones ligeramente más complicadas para agregar una columna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---------+\n",
      "| age|   name|doubleage|\n",
      "+----+-------+---------+\n",
      "|null|Michael|     null|\n",
      "|  30|   Andy|       60|\n",
      "|  19| Justin|       38|\n",
      "+----+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('doubleage',df['age']*2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----------+\n",
      "| age|   name|add_one_age|\n",
      "+----+-------+-----------+\n",
      "|null|Michael|       null|\n",
      "|  30|   Andy|         31|\n",
      "|  19| Justin|         20|\n",
      "+----+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('add_one_age',df['age']+1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+--------+\n",
      "| age|   name|half_age|\n",
      "+----+-------+--------+\n",
      "|null|Michael|    null|\n",
      "|  30|   Andy|    15.0|\n",
      "|  19| Justin|     9.5|\n",
      "+----+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('half_age',df['age']/2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, name: string, half_age: double]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn('half_age',df['age']/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('./data/appl_stock.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>213.429998</td>\n",
       "      <td>214.499996</td>\n",
       "      <td>212.380001</td>\n",
       "      <td>214.009998</td>\n",
       "      <td>123432400</td>\n",
       "      <td>27.727039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>214.599998</td>\n",
       "      <td>215.589994</td>\n",
       "      <td>213.249994</td>\n",
       "      <td>214.379993</td>\n",
       "      <td>150476200</td>\n",
       "      <td>27.774976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>214.379993</td>\n",
       "      <td>215.230000</td>\n",
       "      <td>210.750004</td>\n",
       "      <td>210.969995</td>\n",
       "      <td>138040000</td>\n",
       "      <td>27.333178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>211.750000</td>\n",
       "      <td>212.000006</td>\n",
       "      <td>209.050005</td>\n",
       "      <td>210.580000</td>\n",
       "      <td>119282800</td>\n",
       "      <td>27.282650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>210.299994</td>\n",
       "      <td>212.000006</td>\n",
       "      <td>209.060005</td>\n",
       "      <td>211.980005</td>\n",
       "      <td>111902700</td>\n",
       "      <td>27.464034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>212.799997</td>\n",
       "      <td>213.000002</td>\n",
       "      <td>208.450005</td>\n",
       "      <td>210.110003</td>\n",
       "      <td>115557400</td>\n",
       "      <td>27.221758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>209.189995</td>\n",
       "      <td>209.769995</td>\n",
       "      <td>206.419998</td>\n",
       "      <td>207.720001</td>\n",
       "      <td>148614900</td>\n",
       "      <td>26.912110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-13</td>\n",
       "      <td>207.870005</td>\n",
       "      <td>210.929995</td>\n",
       "      <td>204.099998</td>\n",
       "      <td>210.650002</td>\n",
       "      <td>151473000</td>\n",
       "      <td>27.291720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-01-14</td>\n",
       "      <td>210.110003</td>\n",
       "      <td>210.459997</td>\n",
       "      <td>209.020004</td>\n",
       "      <td>209.430000</td>\n",
       "      <td>108223500</td>\n",
       "      <td>27.133657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>210.929995</td>\n",
       "      <td>211.599997</td>\n",
       "      <td>205.869999</td>\n",
       "      <td>205.930000</td>\n",
       "      <td>148516900</td>\n",
       "      <td>26.680198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High         Low       Close     Volume  \\\n",
       "0 2010-01-04  213.429998  214.499996  212.380001  214.009998  123432400   \n",
       "1 2010-01-05  214.599998  215.589994  213.249994  214.379993  150476200   \n",
       "2 2010-01-06  214.379993  215.230000  210.750004  210.969995  138040000   \n",
       "3 2010-01-07  211.750000  212.000006  209.050005  210.580000  119282800   \n",
       "4 2010-01-08  210.299994  212.000006  209.060005  211.980005  111902700   \n",
       "5 2010-01-11  212.799997  213.000002  208.450005  210.110003  115557400   \n",
       "6 2010-01-12  209.189995  209.769995  206.419998  207.720001  148614900   \n",
       "7 2010-01-13  207.870005  210.929995  204.099998  210.650002  151473000   \n",
       "8 2010-01-14  210.110003  210.459997  209.020004  209.430000  108223500   \n",
       "9 2010-01-15  210.929995  211.599997  205.869999  205.930000  148516900   \n",
       "\n",
       "   Adj Close  \n",
       "0  27.727039  \n",
       "1  27.774976  \n",
       "2  27.333178  \n",
       "3  27.282650  \n",
       "4  27.464034  \n",
       "5  27.221758  \n",
       "6  26.912110  \n",
       "7  27.291720  \n",
       "8  27.133657  \n",
       "9  26.680198  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El filtrado funciona igual que en el caso de los RDDs, nos devuelve los datos que cumplan con cierta condición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>213.429998</td>\n",
       "      <td>214.499996</td>\n",
       "      <td>212.380001</td>\n",
       "      <td>214.009998</td>\n",
       "      <td>123432400</td>\n",
       "      <td>27.727039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>214.599998</td>\n",
       "      <td>215.589994</td>\n",
       "      <td>213.249994</td>\n",
       "      <td>214.379993</td>\n",
       "      <td>150476200</td>\n",
       "      <td>27.774976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>214.379993</td>\n",
       "      <td>215.230000</td>\n",
       "      <td>210.750004</td>\n",
       "      <td>210.969995</td>\n",
       "      <td>138040000</td>\n",
       "      <td>27.333178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>211.750000</td>\n",
       "      <td>212.000006</td>\n",
       "      <td>209.050005</td>\n",
       "      <td>210.580000</td>\n",
       "      <td>119282800</td>\n",
       "      <td>27.282650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>210.299994</td>\n",
       "      <td>212.000006</td>\n",
       "      <td>209.060005</td>\n",
       "      <td>211.980005</td>\n",
       "      <td>111902700</td>\n",
       "      <td>27.464034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High         Low       Close     Volume  \\\n",
       "0 2010-01-04  213.429998  214.499996  212.380001  214.009998  123432400   \n",
       "1 2010-01-05  214.599998  215.589994  213.249994  214.379993  150476200   \n",
       "2 2010-01-06  214.379993  215.230000  210.750004  210.969995  138040000   \n",
       "3 2010-01-07  211.750000  212.000006  209.050005  210.580000  119282800   \n",
       "4 2010-01-08  210.299994  212.000006  209.060005  211.980005  111902700   \n",
       "\n",
       "   Adj Close  \n",
       "0  27.727039  \n",
       "1  27.774976  \n",
       "2  27.333178  \n",
       "3  27.282650  \n",
       "4  27.464034  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.Close < 500).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>1359</td>\n",
       "      <td>1359</td>\n",
       "      <td>1359</td>\n",
       "      <td>1359</td>\n",
       "      <td>1359</td>\n",
       "      <td>1359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>236.47244294334047</td>\n",
       "      <td>238.6941423671817</td>\n",
       "      <td>233.9796908940401</td>\n",
       "      <td>236.36248688079505</td>\n",
       "      <td>8.90163816777042E7</td>\n",
       "      <td>74.93380431788086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>134.63754349125568</td>\n",
       "      <td>135.95868912083253</td>\n",
       "      <td>133.17182943991682</td>\n",
       "      <td>134.5033838014814</td>\n",
       "      <td>6.105617409357081E7</td>\n",
       "      <td>32.3718527953366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.699997</td>\n",
       "      <td>89.470001</td>\n",
       "      <td>90.279999</td>\n",
       "      <td>11475900</td>\n",
       "      <td>24.881912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>514.259995</td>\n",
       "      <td>526.290016</td>\n",
       "      <td>496.88998399999997</td>\n",
       "      <td>499.779984</td>\n",
       "      <td>470249500</td>\n",
       "      <td>127.96609099999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                Open                High                 Low  \\\n",
       "0   count                1359                1359                1359   \n",
       "1    mean  236.47244294334047   238.6941423671817   233.9796908940401   \n",
       "2  stddev  134.63754349125568  135.95868912083253  133.17182943991682   \n",
       "3     min                90.0           90.699997           89.470001   \n",
       "4     max          514.259995          526.290016  496.88998399999997   \n",
       "\n",
       "                Close               Volume           Adj Close  \n",
       "0                1359                 1359                1359  \n",
       "1  236.36248688079505   8.90163816777042E7   74.93380431788086  \n",
       "2   134.5033838014814  6.105617409357081E7    32.3718527953366  \n",
       "3           90.279999             11475900           24.881912  \n",
       "4          499.779984            470249500  127.96609099999999  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.Close < 500).describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>213.429998</td>\n",
       "      <td>214.499996</td>\n",
       "      <td>212.380001</td>\n",
       "      <td>214.009998</td>\n",
       "      <td>123432400</td>\n",
       "      <td>27.727039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>214.599998</td>\n",
       "      <td>215.589994</td>\n",
       "      <td>213.249994</td>\n",
       "      <td>214.379993</td>\n",
       "      <td>150476200</td>\n",
       "      <td>27.774976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>214.379993</td>\n",
       "      <td>215.230000</td>\n",
       "      <td>210.750004</td>\n",
       "      <td>210.969995</td>\n",
       "      <td>138040000</td>\n",
       "      <td>27.333178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>211.750000</td>\n",
       "      <td>212.000006</td>\n",
       "      <td>209.050005</td>\n",
       "      <td>210.580000</td>\n",
       "      <td>119282800</td>\n",
       "      <td>27.282650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>210.299994</td>\n",
       "      <td>212.000006</td>\n",
       "      <td>209.060005</td>\n",
       "      <td>211.980005</td>\n",
       "      <td>111902700</td>\n",
       "      <td>27.464034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High         Low       Close     Volume  \\\n",
       "0 2010-01-04  213.429998  214.499996  212.380001  214.009998  123432400   \n",
       "1 2010-01-05  214.599998  215.589994  213.249994  214.379993  150476200   \n",
       "2 2010-01-06  214.379993  215.230000  210.750004  210.969995  138040000   \n",
       "3 2010-01-07  211.750000  212.000006  209.050005  210.580000  119282800   \n",
       "4 2010-01-08  210.299994  212.000006  209.060005  211.980005  111902700   \n",
       "\n",
       "   Adj Close  \n",
       "0  27.727039  \n",
       "1  27.774976  \n",
       "2  27.333178  \n",
       "3  27.282650  \n",
       "4  27.464034  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Otro modo de hacerlo\n",
    "df.filter(\"Close < 500\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede ser que yo no quiera ver todo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|              Open|             Close|\n",
      "+------------------+------------------+\n",
      "|        213.429998|        214.009998|\n",
      "|        214.599998|        214.379993|\n",
      "|        214.379993|        210.969995|\n",
      "|            211.75|            210.58|\n",
      "|        210.299994|211.98000499999998|\n",
      "|212.79999700000002|210.11000299999998|\n",
      "|209.18999499999998|        207.720001|\n",
      "|        207.870005|        210.650002|\n",
      "|210.11000299999998|            209.43|\n",
      "|210.92999500000002|            205.93|\n",
      "|        208.330002|        215.039995|\n",
      "|        214.910006|            211.73|\n",
      "|        212.079994|        208.069996|\n",
      "|206.78000600000001|            197.75|\n",
      "|202.51000200000001|        203.070002|\n",
      "|205.95000100000001|        205.940001|\n",
      "|        206.849995|        207.880005|\n",
      "|        204.930004|        199.289995|\n",
      "|        201.079996|        192.060003|\n",
      "|192.36999699999998|        194.729998|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Close < 500\").select(['Open','Close']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, entonces, ¿qué hacen los siguientes comandos de spark con nuestro DF original?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-22</td>\n",
       "      <td>206.780006</td>\n",
       "      <td>207.499996</td>\n",
       "      <td>197.160000</td>\n",
       "      <td>197.750000</td>\n",
       "      <td>220441900</td>\n",
       "      <td>25.620401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-28</td>\n",
       "      <td>204.930004</td>\n",
       "      <td>205.500004</td>\n",
       "      <td>198.699995</td>\n",
       "      <td>199.289995</td>\n",
       "      <td>293375600</td>\n",
       "      <td>25.819922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-29</td>\n",
       "      <td>201.079996</td>\n",
       "      <td>202.199995</td>\n",
       "      <td>190.250002</td>\n",
       "      <td>192.060003</td>\n",
       "      <td>311488100</td>\n",
       "      <td>24.883208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High         Low       Close     Volume  \\\n",
       "0 2010-01-22  206.780006  207.499996  197.160000  197.750000  220441900   \n",
       "1 2010-01-28  204.930004  205.500004  198.699995  199.289995  293375600   \n",
       "2 2010-01-29  201.079996  202.199995  190.250002  192.060003  311488100   \n",
       "\n",
       "   Adj Close  \n",
       "0  25.620401  \n",
       "1  25.819922  \n",
       "2  24.883208  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((df['Close'] < 200) & (df['Open'] > 200)).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>192.369997</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>191.299999</td>\n",
       "      <td>194.729998</td>\n",
       "      <td>187469100</td>\n",
       "      <td>25.229131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-02</td>\n",
       "      <td>195.909998</td>\n",
       "      <td>196.319994</td>\n",
       "      <td>193.379993</td>\n",
       "      <td>195.859997</td>\n",
       "      <td>174585600</td>\n",
       "      <td>25.375533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-03</td>\n",
       "      <td>195.169994</td>\n",
       "      <td>200.200003</td>\n",
       "      <td>194.420004</td>\n",
       "      <td>199.229994</td>\n",
       "      <td>153832000</td>\n",
       "      <td>25.812149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-04</td>\n",
       "      <td>196.730003</td>\n",
       "      <td>198.370001</td>\n",
       "      <td>191.570005</td>\n",
       "      <td>192.050003</td>\n",
       "      <td>189413000</td>\n",
       "      <td>24.881912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>192.630003</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>190.850002</td>\n",
       "      <td>195.460001</td>\n",
       "      <td>212576700</td>\n",
       "      <td>25.323710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High         Low       Close     Volume  \\\n",
       "0 2010-02-01  192.369997  196.000000  191.299999  194.729998  187469100   \n",
       "1 2010-02-02  195.909998  196.319994  193.379993  195.859997  174585600   \n",
       "2 2010-02-03  195.169994  200.200003  194.420004  199.229994  153832000   \n",
       "3 2010-02-04  196.730003  198.370001  191.570005  192.050003  189413000   \n",
       "4 2010-02-05  192.630003  196.000000  190.850002  195.460001  212576700   \n",
       "\n",
       "   Adj Close  \n",
       "0  25.229131  \n",
       "1  25.375533  \n",
       "2  25.812149  \n",
       "3  24.881912  \n",
       "4  25.323710  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((df['Close'] < 200) & ~(df['Open'] > 200)).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-22</td>\n",
       "      <td>206.780006</td>\n",
       "      <td>207.499996</td>\n",
       "      <td>197.16</td>\n",
       "      <td>197.75</td>\n",
       "      <td>220441900</td>\n",
       "      <td>25.620401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High     Low   Close     Volume  Adj Close\n",
       "0 2010-01-22  206.780006  207.499996  197.16  197.75  220441900  25.620401"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((df['Low'] == 197.16)).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podemos guardar información que nos interese particularmente en un diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.filter((df['Low'] == 197.16)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': datetime.datetime(2010, 1, 22, 0, 0),\n",
       " 'Open': 206.78000600000001,\n",
       " 'High': 207.499996,\n",
       " 'Low': 197.16,\n",
       " 'Close': 197.75,\n",
       " 'Volume': 220441900,\n",
       " 'Adj Close': 25.620401}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220441900"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.asDict()['Volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## groupBy y aggregate\n",
    "* groupBy: agrupa datos juntos con base en los valores de alguna columna\n",
    "* aggregate: combines aggregates combina y/o agrega en una sola salida (como las sumas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('./data/sales_info.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(6).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Person: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|Company|       avg(Sales)|\n",
      "+-------+-----------------+\n",
      "|   APPL|            370.0|\n",
      "|   GOOG|            220.0|\n",
      "|     FB|            610.0|\n",
      "|   MSFT|322.3333333333333|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|sum(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|    1480.0|\n",
      "|   GOOG|     660.0|\n",
      "|     FB|    1220.0|\n",
      "|   MSFT|     967.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|max(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|     750.0|\n",
      "|   GOOG|     340.0|\n",
      "|     FB|     870.0|\n",
      "|   MSFT|     600.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").max().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aggregate\n",
    "\n",
    "<div class=\"alert alert-info\"> Cuando no agregamos GroupBy, solamente estamos agregando a través de todo </div>\n",
    "\n",
    "<div class=\"alert alert-info\"> Una de las formas de agregar es usar un diccionario como entrada </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(Sales)|\n",
      "+----------+\n",
      "|    4327.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({'Sales':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max(Sales)|\n",
      "+----------+\n",
      "|     870.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({'Sales':'max'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Con grupo de agregación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = df.groupBy(\"Company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|max(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|     750.0|\n",
      "|   GOOG|     340.0|\n",
      "|     FB|     870.0|\n",
      "|   MSFT|     600.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_data.agg({'Sales':'max'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay más fucnciones de agregación como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct,avg,stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "### Cargar el Walmart stock CSV File, con Spark infiriendo el esquema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('./data/walmart_stock.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo se llaman las columnas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo se ve el esquema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo imprimirían las primeras cinco líneas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo usamos describe para aprender del DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La media y la desviación estándar nos muestran muchooos puntos decimales. Podemos formatear los números para mostrarnos tan sólo hasta dos decimales. \n",
    "\n",
    "(Hint, primero hay que checar el esquema de describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+--------+--------+\n",
      "|summary|    Open|    High|     Low|   Close|  Volume|\n",
      "+-------+--------+--------+--------+--------+--------+\n",
      "|  count|1,258.00|1,258.00|1,258.00|1,258.00|    1258|\n",
      "|   mean|   72.36|   72.84|   71.92|   72.39| 8222093|\n",
      "| stddev|    6.77|    6.77|    6.74|    6.76| 4519780|\n",
      "|    min|   56.39|   57.06|   56.30|   56.42| 2094900|\n",
      "|    max|   90.80|   90.97|   89.25|   90.47|80898100|\n",
      "+-------+--------+--------+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import format_number\n",
    "result = df.describe()\n",
    "result2 = result.select(result['summary'],\n",
    "              format_number(result['Open'].cast('float'),2).alias('Open'),\n",
    "              format_number(result['High'].cast('float'),2).alias('High'),\n",
    "              format_number(result['Low'].cast('float'),2).alias('Low'),\n",
    "              format_number(result['Close'].cast('float'),2).alias('Close'),\n",
    "              result['Volume'].cast('int').alias('Volume')\n",
    "             )\n",
    "result2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crea un nuevo DataFrame con una columna que se llame HV Ratio que sea el cociente de el High Prices vs el volumen del stock (Volume)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            HV Ratio|\n",
      "+--------------------+\n",
      "|4.819714653321546E-6|\n",
      "|6.290848613094555E-6|\n",
      "|4.669412994783916E-6|\n",
      "|7.367338463826307E-6|\n",
      "|8.915604778943901E-6|\n",
      "|8.644477436914568E-6|\n",
      "|9.351828421515645E-6|\n",
      "| 8.29141562102703E-6|\n",
      "|7.712212102001476E-6|\n",
      "|7.071764823529412E-6|\n",
      "|1.015495466386981E-5|\n",
      "|6.576354146362592...|\n",
      "| 5.90145296180676E-6|\n",
      "|8.547679455011844E-6|\n",
      "|8.420709512685392E-6|\n",
      "|1.041448341728929...|\n",
      "|8.316075414862431E-6|\n",
      "|9.721183814992126E-6|\n",
      "|8.029436027707578E-6|\n",
      "|6.307432259386365E-6|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    (df.High/df.Volume).alias(\"HV Ratio\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué día fue el pico más alto en High?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Date=datetime.datetime(2015, 1, 13, 0, 0), Open=90.800003, High=90.970001, Low=88.93, Close=89.309998, Volume=8215400, Adj Close=83.825448)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Didn't need to really do this much indexing\n",
    "# Could have just shown the entire row\n",
    "df.orderBy(df[\"High\"].desc()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2015, 1, 13, 0, 0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orderBy(df[\"High\"].desc()).head(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuál es la media de la columna Close?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col as c\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|MEAN_Close|\n",
      "+----------+\n",
      "|  72.38845|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    " F.avg(df[\"Close\"].cast('Float')).cast('Float').alias(\"MEAN_Close\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(Close)|\n",
      "+-----------------+\n",
      "|72.38844998012726|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.mean(\"Close\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuáles son el máximo y el mínimo de la columna Volume?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|max(Volume)|min(Volume)|\n",
      "+-----------+-----------+\n",
      "|   80898100|    2094900|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    F.max(\"Volume\"),\n",
    "    F.min(\"Volume\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuál fue el máximo High al año?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>59.970001</td>\n",
       "      <td>61.060001</td>\n",
       "      <td>59.869999</td>\n",
       "      <td>60.330002</td>\n",
       "      <td>12668800</td>\n",
       "      <td>52.619235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>60.209999</td>\n",
       "      <td>60.349998</td>\n",
       "      <td>59.470001</td>\n",
       "      <td>59.709999</td>\n",
       "      <td>9593300</td>\n",
       "      <td>52.078475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>59.349998</td>\n",
       "      <td>59.619999</td>\n",
       "      <td>58.369999</td>\n",
       "      <td>59.419998</td>\n",
       "      <td>12768200</td>\n",
       "      <td>51.825539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open       High        Low      Close    Volume  Adj Close\n",
       "0 2012-01-03  59.970001  61.060001  59.869999  60.330002  12668800  52.619235\n",
       "1 2012-01-04  60.209999  60.349998  59.470001  59.709999   9593300  52.078475\n",
       "2 2012-01-05  59.349998  59.619999  58.369999  59.419998  12768200  51.825539"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.select('*',\n",
    "          F.year(\"Date\").alias('year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|year|max(High)|\n",
      "+----+---------+\n",
      "|2015|90.970001|\n",
      "|2013|81.370003|\n",
      "|2014|88.089996|\n",
      "|2012|77.599998|\n",
      "|2016|75.190002|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy('year').max('High').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursos\n",
    "- [About Spark in mapr](https://mapr.com/blog/spark-101-what-it-what-it-does-and-why-it-matters/)\n",
    "- [edX course Big Data analytics Using Spark](https://courses.edx.org/courses/course-v1:UCSanDiegoX+DSE230x+1T2018/courseware/2966295eefb4492b836de9ee34f05911/56608329f8fc42fc8fcaa5e49673ee3b/5?activate_block_id=block-v1%3AUCSanDiegoX%2BDSE230x%2B1T2018%2Btype%40vertical%2Bblock%4042ff48e505e24071b920a496b48a32bc)\n",
    "- [paper regarding RDDs](https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf)\n",
    "- [saurzcode on what is RDD](https://saurzcode.in/2015/10/what-is-rdd-in-spark-and-why-do-we-need-it/)\n",
    "- [Spark-py notebooks by Jose A. Dianes](https://github.com/jadianes/spark-py-notebooks)\n",
    "- [Presenting code using Jupyter Notebook Slides](https://medium.com/@mjspeck/presenting-code-using-jupyter-notebook-slides-a8a3c3b59d67)\n",
    "- http://dme.rwth-aachen.de/en/research/projects/mapreduce\n",
    "- https://softwareengineering.stackexchange.com/questions/98800/is-mapreduce-anything-more-than-just-an-application-of-divide-and-conquer\n",
    "- http://data-flair.training/forums/topic/sparksession-vs-sparkcontext-in-apache-spark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
